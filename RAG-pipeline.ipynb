{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Auroraaa17/RAG-pipeline/blob/main/RAG-pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96Pl_sw4m_Dy"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes\n",
        "!pip install sentence_transformers\n",
        "!pip install llama_index\n",
        "!pip install llama-index-llms-huggingface\n",
        "!pip install langchain_community\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLyIEkfCoWQ_"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
        "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader,ServiceContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaN_NkkoQ32X"
      },
      "outputs": [],
      "source": [
        "Documents = SimpleDirectoryReader(\"/content/arxiv_papers\").load_data()\n",
        "Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4H6cyubKRnE"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.llm import LLMChain\n",
        "\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are a friendly chatbot assistant that gives structured output.\n",
        "Your role is to arrange given task in this structure.\n",
        "### instruction:\n",
        "{instruction}\n",
        "Output:\n",
        "\"\"\"\n",
        "task_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"instruction\"], template=system_prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Y7dOlK9Q32Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb5ebf6-1340-4561-bdfe-40b888ab1ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: ··········\n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from huggingface_hub import interpreter_login\n",
        "\n",
        "interpreter_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WaRHM3nQ32Z"
      },
      "outputs": [],
      "source": [
        " !pip install -i https://pypi.org/simple/ bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubeo0Xq7rFcU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "de7a037412a54d4db1ab3d6ff2ff054c",
            "24a31c7b2ed3483aa188490d96e4a54f",
            "03005ce195104be78ed136ad70492b02",
            "1f26b00a7df3494baf8091a8389ddf59",
            "24485c5733a34d8dbd6fc94c940e096e",
            "9f4b167cfbe34d3e85658f7dd1a13ecf",
            "c7e5fe54be13471a9ffee1ee9098a2de",
            "8dbb6b13150146a9ab3ca3f458c83bfd",
            "fb0ca2bd3ec64ca1b54c82bf6a055240",
            "523aa20d398b43c6bc9cb77a234e6e97",
            "1f54ba590fc84bf8896c18de0f23125c"
          ]
        },
        "outputId": "cfec5388-aec0-425a-8c1d-9e39709a773b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1363: UserWarning: Current model requires 16779264 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de7a037412a54d4db1ab3d6ff2ff054c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n",
            "WARNING:llama_index.llms.huggingface.base:Supplied context_window 5000 is greater than the model's max input size 2048. Disable this warning by setting a lower context_window.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import AutoTokenizer, PhiForCausalLM\n",
        "\n",
        "#from accelerate import disk_offload\n",
        "#from transformers import AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "#model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", offload_folder=\"save_folder\", torch_dtype=torch.float16, low_cpu_mem_usage = True).cpu()\n",
        "#from accelerate import disk_offload\n",
        "#disk_offload(model=model,offload_dir= \"offload_directory\" )\n",
        "\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_8bit=True, llm_int8_threshold=200.0)\n",
        "#model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\", torch_dtype=torch.float16, low_cpu_mem_usage = True).cpu()\n",
        "#from accelerate import disk_offload\n",
        "#disk_offload(model=model, offload_dir=\"offload\")\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=5000,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\" : 0.0, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "\n",
        "    tokenizer_name = \"microsoft/phi-2\",\n",
        "    model_name = \"microsoft/phi-2\",\n",
        "    device_map = \"auto\",\n",
        "    #quantization_config=quantization_config,\n",
        ")\n",
        "    #model_kwargs ={\"torch_dtype\" : torch.float16, \"load_in_8bit\" : True}\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)  # execs code downloaded from hf hub\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pbGCCg65Gpe"
      },
      "outputs": [],
      "source": [
        "pip install llama-index-embeddings-langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7N9RUkBu--o"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index.core import ServiceContext\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-yEYtK55fCu"
      },
      "outputs": [],
      "source": [
        "pip install -U sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsD-7pT24HBU"
      },
      "outputs": [],
      "source": [
        "embed_model = LangchainEmbedding(\n",
        "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf0YzC9w54cJ"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "# maximum input size to the LLM\n",
        "Settings.context_window = 4096\n",
        "\n",
        "# number of tokens reserved for text generation.\n",
        "Settings.num_output = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j60sw8kM6Uh-"
      },
      "outputs": [],
      "source": [
        "\n",
        "from llama_index.core import VectorStoreIndex\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    Documents, embed_model=embed_model)\n",
        "\n",
        "\n",
        "query_engine = index.as_query_engine(llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zPN7FDW6l4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de0427a-fd66-41a8-84b4-e11a96d6fc3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"What is CRUD?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "Vl7gMnf5hRH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e588a1a-ad86-458e-85aa-e0145ec23722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models 111:3\n",
            "Fig. 1. We have classified the application scenarios of RAG into four primary aspects: Create, Read, Update,\n",
            "and Delete. The figure provides an illustrative example for each category, showcasing the wide-ranging\n",
            "potential of RAG technology.\n",
            "we can use the CRUD framework to classify the RAG systems’ application scenarios. As shown in\n",
            "Figure 1, each CRUD category demonstrates different capabilities of the RAG system:\n",
            "•In \"CREATE \", the system improves the input text by adding relevant information from\n",
            "external sources, making creative outputs such as poetry, stories, or code.\n",
            "•In \"READ \", the system uses external knowledge retrieval to answer questions, solving\n",
            "problems in question-answering, dialogue, and reasoning, and increasing understanding of\n",
            "the input text.\n",
            "•In \"UPDATE \", the system fixes errors in the input text using retrieved content, correcting\n",
            "spelling, grammar or factual errors to make the text better.\n",
            "•In \"DELETE \", the system simplifies the input by improving retrieval results, removing\n",
            "unnecessary details, and doing tasks like\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de7a037412a54d4db1ab3d6ff2ff054c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24a31c7b2ed3483aa188490d96e4a54f",
              "IPY_MODEL_03005ce195104be78ed136ad70492b02",
              "IPY_MODEL_1f26b00a7df3494baf8091a8389ddf59"
            ],
            "layout": "IPY_MODEL_24485c5733a34d8dbd6fc94c940e096e"
          }
        },
        "24a31c7b2ed3483aa188490d96e4a54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f4b167cfbe34d3e85658f7dd1a13ecf",
            "placeholder": "​",
            "style": "IPY_MODEL_c7e5fe54be13471a9ffee1ee9098a2de",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "03005ce195104be78ed136ad70492b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dbb6b13150146a9ab3ca3f458c83bfd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb0ca2bd3ec64ca1b54c82bf6a055240",
            "value": 2
          }
        },
        "1f26b00a7df3494baf8091a8389ddf59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_523aa20d398b43c6bc9cb77a234e6e97",
            "placeholder": "​",
            "style": "IPY_MODEL_1f54ba590fc84bf8896c18de0f23125c",
            "value": " 2/2 [00:24&lt;00:00, 24.04s/it]"
          }
        },
        "24485c5733a34d8dbd6fc94c940e096e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f4b167cfbe34d3e85658f7dd1a13ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7e5fe54be13471a9ffee1ee9098a2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dbb6b13150146a9ab3ca3f458c83bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0ca2bd3ec64ca1b54c82bf6a055240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "523aa20d398b43c6bc9cb77a234e6e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f54ba590fc84bf8896c18de0f23125c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}